{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency Analysis\n",
    "\n",
    "This notebook calculates per-lifter performance variance (CV) and identifies consistency patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from utils import categorize_ipf_weightclass, map_division_to_age_group, categorize_age_group, create_quality_filter, categorize_lifters, categorize_federation_testing_status\n",
    "\n",
    "# Load the processed dataset\n",
    "df = pd.read_parquet(\"../data/processed/full_dataset.parquet\")\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# Add IPF Weight Class categorization (needed for quality filter)\n",
    "if 'BodyweightKg' in df.columns and 'Sex' in df.columns:\n",
    "    df['IPF_WeightClass'] = df.apply(\n",
    "        lambda row: categorize_ipf_weightclass(row['BodyweightKg'], row['Sex']), \n",
    "        axis=1\n",
    "    )\n",
    "# Apply quality filter (excludes outliers and invalid data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APPLYING QUALITY FILTER\")\n",
    "print(\"=\"*80)\n",
    "quality_mask = create_quality_filter(df)\n",
    "filtered_out = (~quality_mask).sum()\n",
    "print(f\"Quality filter will exclude {filtered_out:,} entries ({filtered_out/len(df)*100:.2f}%)\")\n",
    "print(f\"  Remaining entries for analysis: {quality_mask.sum():,} ({quality_mask.sum()/len(df)*100:.2f}%)\")\n",
    "# Create clean dataset (filtered)\n",
    "df = df[quality_mask].copy()\n",
    "# Add Age Group categorization from Division (100% coverage)\n",
    "if 'Division' in df.columns:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ADDING AGE GROUP CATEGORIZATION\")\n",
    "    print(\"=\"*80)\n",
    "    df['AgeGroup'] = df['Division'].apply(map_division_to_age_group)\n",
    "    print(\"Age Group categorization complete (using Division - 100% coverage)\")\n",
    "    if 'AgeGroup' in df.columns:\n",
    "        print(f\"Age Group distribution:\\n{df['AgeGroup'].value_counts()}\")\n",
    "else:\n",
    "    print(\"Warning: Cannot add Age Group - missing Division column\")\n",
    "    df['AgeGroup'] = None\n",
    "print(f\"\\n✓ Using filtered dataset with {len(df):,} entries\")\n",
    "# Categorize lifters (New/Intermediate/Advanced)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CATEGORIZING LIFTERS\")\n",
    "print(\"=\"*80)\n",
    "df = categorize_lifters(df)\n",
    "print(\"✓ Lifters categorized into New, Intermediate, and Advanced\")\n",
    "\n",
    "# Categorize federation testing status (Drug Tested vs Untested)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CATEGORIZING FEDERATION TESTING STATUS\")\n",
    "print(\"=\"*80)\n",
    "df = categorize_federation_testing_status(df)\n",
    "testing_status_counts = df['FederationTestingStatus'].value_counts()\n",
    "print(\"Federation Testing Status distribution:\")\n",
    "print(testing_status_counts)\n",
    "print(f\"✓ Federation testing status categorized\")\n",
    "# Create separate datasets for each category\n",
    "if 'LifterCategory' in df.columns:\n",
    "    new_lifters_df = df[df['LifterCategory'] == 'New'].copy()\n",
    "    intermediate_lifters_df = df[df['LifterCategory'] == 'Intermediate'].copy()\n",
    "    advanced_lifters_df = df[df['LifterCategory'] == 'Advanced'].copy()\n",
    "    \n",
    "    print(f\"\\nCategory breakdown:\")\n",
    "    print(f\"  New lifters: {len(new_lifters_df):,} entries\")\n",
    "    print(f\"  Intermediate lifters: {len(intermediate_lifters_df):,} entries\")\n",
    "    print(f\"  Advanced lifters: {len(advanced_lifters_df):,} entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the processed dataset\n",
    "df = pd.read_parquet(\"../data/processed/full_dataset.parquet\")\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate Consistency Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Dots or Wilks as base score if available\n",
    "if 'Dots' in df.columns:\n",
    "    base_score_col = 'Dots'\n",
    "elif 'Wilks' in df.columns:\n",
    "    base_score_col = 'Wilks'\n",
    "else:\n",
    "    base_score_col = 'TotalKg'\n",
    "\n",
    "# Filter to valid performance data\n",
    "analysis_df = df[(df[base_score_col].notna()) & (df[base_score_col] > 0)].copy()\n",
    "\n",
    "print(f\"Using {base_score_col} as performance metric\")\n",
    "print(f\"Analysis dataset: {len(analysis_df):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-lifter consistency metrics\n",
    "# Only analyze lifters with at least 3 meets\n",
    "if 'Name' in analysis_df.columns:\n",
    "    lifter_stats = analysis_df.groupby('Name').agg({\n",
    "        base_score_col: ['count', 'mean', 'std', 'min', 'max'],\n",
    "        'MeetDate': ['min', 'max']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    lifter_stats.columns = ['Name', 'MeetCount', 'MeanScore', 'StdScore', 'MinScore', 'MaxScore', \n",
    "                           'FirstMeet', 'LastMeet']\n",
    "    \n",
    "    # Filter to lifters with at least 3 meets\n",
    "    lifter_stats = lifter_stats[lifter_stats['MeetCount'] >= 3].copy()\n",
    "    \n",
    "    # Calculate coefficient of variation (CV) = std/mean\n",
    "    lifter_stats['CV'] = lifter_stats['StdScore'] / lifter_stats['MeanScore']\n",
    "    \n",
    "    # Calculate peak vs average ratio\n",
    "    lifter_stats['PeakToAvgRatio'] = lifter_stats['MaxScore'] / lifter_stats['MeanScore']\n",
    "    \n",
    "    # Calculate improvement trend (simple: last - first)\n",
    "    lifter_first_last = analysis_df.groupby('Name').apply(\n",
    "        lambda x: pd.Series({\n",
    "            'FirstScore': x.sort_values('MeetDate').iloc[0][base_score_col],\n",
    "            'LastScore': x.sort_values('MeetDate').iloc[-1][base_score_col]\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    lifter_stats = lifter_stats.merge(lifter_first_last, on='Name', how='left')\n",
    "    lifter_stats['Improvement'] = lifter_stats['LastScore'] - lifter_stats['FirstScore']\n",
    "    lifter_stats['ImprovementPct'] = (lifter_stats['Improvement'] / lifter_stats['FirstScore']) * 100\n",
    "    \n",
    "    print(f\"Analyzed {len(lifter_stats):,} lifters with 3+ meets\")\n",
    "    print(f\"\\nConsistency statistics:\")\n",
    "    print(lifter_stats[['MeetCount', 'CV', 'PeakToAvgRatio', 'ImprovementPct']].describe())\n",
    "else:\n",
    "    print(\"Name column not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Consistency Distribution Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize consistency metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# CV distribution\n",
    "ax1 = axes[0, 0]\n",
    "lifter_stats['CV'].hist(bins=50, edgecolor='black', alpha=0.7, ax=ax1)\n",
    "ax1.axvline(lifter_stats['CV'].median(), color='r', linestyle='--', \n",
    "           label=f'Median: {lifter_stats[\"CV\"].median():.3f}')\n",
    "ax1.set_xlabel('Coefficient of Variation (CV)')\n",
    "ax1.set_ylabel('Number of Lifters')\n",
    "ax1.set_title('Distribution of Performance Consistency (CV)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Peak to average ratio\n",
    "ax2 = axes[0, 1]\n",
    "lifter_stats['PeakToAvgRatio'].hist(bins=50, edgecolor='black', alpha=0.7, ax=ax2)\n",
    "ax2.axvline(lifter_stats['PeakToAvgRatio'].median(), color='r', linestyle='--',\n",
    "           label=f'Median: {lifter_stats[\"PeakToAvgRatio\"].median():.3f}')\n",
    "ax2.set_xlabel('Peak to Average Ratio')\n",
    "ax2.set_ylabel('Number of Lifters')\n",
    "ax2.set_title('Distribution of Peak vs Average Performance')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# CV vs Meet Count\n",
    "ax3 = axes[1, 0]\n",
    "sample_lifters = lifter_stats.sample(min(5000, len(lifter_stats)))\n",
    "ax3.scatter(sample_lifters['MeetCount'], sample_lifters['CV'], alpha=0.3, s=10)\n",
    "ax3.set_xlabel('Number of Meets')\n",
    "ax3.set_ylabel('Coefficient of Variation (CV)')\n",
    "ax3.set_title('Consistency vs Experience')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Improvement percentage distribution\n",
    "ax4 = axes[1, 1]\n",
    "lifter_stats['ImprovementPct'].hist(bins=50, edgecolor='black', alpha=0.7, ax=ax4)\n",
    "ax4.axvline(0, color='r', linestyle='--', label='No change')\n",
    "ax4.axvline(lifter_stats['ImprovementPct'].median(), color='g', linestyle='--',\n",
    "           label=f'Median: {lifter_stats[\"ImprovementPct\"].median():.1f}%')\n",
    "ax4.set_xlabel('Improvement Percentage (%)')\n",
    "ax4.set_ylabel('Number of Lifters')\n",
    "ax4.set_title('Distribution of Career Improvement')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/consistency_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify Highly Consistent vs Variable Lifters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize lifters by consistency\n",
    "lifter_stats['ConsistencyCategory'] = pd.cut(\n",
    "    lifter_stats['CV'],\n",
    "    bins=[0, 0.05, 0.10, 0.20, float('inf')],\n",
    "    labels=['Very Consistent', 'Consistent', 'Variable', 'Highly Variable']\n",
    ")\n",
    "\n",
    "print(\"=== Consistency Categories ===\")\n",
    "print(lifter_stats['ConsistencyCategory'].value_counts())\n",
    "print(f\"\\nCategory statistics:\")\n",
    "# Show consistency by category, split by testing status\n",
    "for testing_status in ['Drug Tested', 'Untested']:\n",
    "    status_lifter_stats = lifter_stats[lifter_stats['FederationTestingStatus'] == testing_status]\n",
    "    if len(status_lifter_stats) > 0:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"CONSISTENCY BY CATEGORY - {testing_status.upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(status_lifter_stats.groupby('ConsistencyCategory', observed=True)[['MeanScore', 'MeetCount', 'ImprovementPct']].agg(['mean', 'median']))\n",
    "\n",
    "# Identify most and least consistent lifters\n",
    "print(f\"\\n=== Most Consistent Lifters (Top 10) ===\")\n",
    "most_consistent = lifter_stats.nsmallest(10, 'CV')[['Name', 'MeetCount', 'MeanScore', 'CV', 'PeakToAvgRatio']]\n",
    "print(most_consistent.to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== Least Consistent Lifters (Top 10) ===\")\n",
    "least_consistent = lifter_stats.nlargest(10, 'CV')[['Name', 'MeetCount', 'MeanScore', 'CV', 'PeakToAvgRatio']]\n",
    "print(least_consistent.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Findings Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Consistency Analysis Summary ===\")\n",
    "print(f\"\\n1. Lifters analyzed (3+ meets): {len(lifter_stats):,}\")\n",
    "\n",
    "# Summary split by testing status\n",
    "for testing_status in ['Drug Tested', 'Untested']:\n",
    "    status_lifter_stats = lifter_stats[lifter_stats['FederationTestingStatus'] == testing_status]\n",
    "    if len(status_lifter_stats) > 0:\n",
    "        print(f\"\\n{testing_status.upper()}:\")\n",
    "        print(f\"  2. Average CV: {status_lifter_stats['CV'].mean():.3f}\")\n",
    "        print(f\"  3. Median CV: {status_lifter_stats['CV'].median():.3f}\")\n",
    "        print(f\"  4. Average peak-to-average ratio: {status_lifter_stats['PeakToAvgRatio'].mean():.3f}\")\n",
    "        print(f\"  5. Average improvement: {status_lifter_stats['ImprovementPct'].mean():.2f}%\")\n",
    "        print(f\"  6. Correlation: CV vs Meet Count: {status_lifter_stats['CV'].corr(status_lifter_stats['MeetCount']):.3f}\")\n",
    "\n",
    "# Save consistency metrics\n",
    "lifter_stats.to_parquet('../data/processed/consistency_metrics.parquet', index=False)\n",
    "print(\"\\nConsistency metrics saved to ../data/processed/consistency_metrics.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
