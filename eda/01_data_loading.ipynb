{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be7f4c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80012dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPF: Loaded 265 entries files, 265 meets files\n",
      "USAPL: Loaded 4206 entries files, 4206 meets files\n",
      "PA: Loaded 951 entries files, 951 meets files\n",
      "\n",
      "============================================================\n",
      "COMBINED RESULTS:\n",
      "============================================================\n",
      "Total entries: 362415\n",
      "Total meets: 5422\n",
      "\n",
      "Entries breakdown:\n",
      "  - IPF: 52706 entries\n",
      "  - USAPL: 284587 entries\n",
      "  - PA: 25122 entries\n",
      "\n",
      "Meets breakdown:\n",
      "  - IPF: 265 meets\n",
      "  - USAPL: 4206 meets\n",
      "  - PA: 951 meets\n",
      "\n",
      "Entries dataframe shape: (362415, 52)\n",
      "Meets dataframe shape: (5422, 7)\n",
      "Age still missing: 24583\n",
      "\n",
      "Age statistics:\n",
      "count    381957.000000\n",
      "mean         29.745970\n",
      "std          13.333483\n",
      "min           7.991786\n",
      "25%          20.000000\n",
      "50%          25.000000\n",
      "75%          36.000000\n",
      "max          94.000000\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "============================================================\n",
      "AFTER MERGE:\n",
      "============================================================\n",
      "Entries dataframe shape: (406540, 58)\n",
      "Columns: ['Name', 'Division', 'BirthYear', 'BirthDate', 'WeightClassKg', 'BodyweightKg', 'Country', 'Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg', 'TotalKg', 'Event', 'Equipment', 'Sex', 'Place', 'MeetID', 'Deadlift4Kg', 'Bench4Kg', 'Bench1Kg', 'Bench2Kg', 'Bench3Kg', 'Team', 'Squat4Kg', 'Squat1Kg', 'Squat2Kg', 'Squat3Kg', 'Deadlift1Kg', 'Deadlift2Kg', 'Deadlift3Kg', 'Age', 'State', 'Tested', 'AgeRange', 'DeadliftEquipment', 'CyrillicName', 'ChineseName', 'KoreanName', 'BodyweightLbs', 'WeightClassLbs', 'Squat1Lbs', 'Squat2Lbs', 'Squat3Lbs', 'Best3SquatLbs', 'Bench1Lbs', 'Bench2Lbs', 'Bench3Lbs', 'Best3BenchLbs', 'Deadlift1Lbs', 'Deadlift2Lbs', 'Deadlift3Lbs', 'Best3DeadliftLbs', 'TotalLbs', 'Federation', 'Date', 'MeetCountry', 'MeetState', 'MeetTown', 'MeetName']\n",
      "\n",
      "Date column info:\n",
      "  - Non-null dates: 406540\n",
      "  - Date range: 1973-11-09 00:00:00 to 2025-12-24 00:00:00\n",
      "\n",
      "First few rows with merged data:\n",
      "                  Name MeetID       Date Division Sex WeightClassKg  \\\n",
      "0    Andrzej Stanaszek   0001 2000-11-15     Open   M            52   \n",
      "1    Andrzej Stanaszek   0001 2000-02-27     Open   M            52   \n",
      "2  Sergey Zhuravlev #1   0001 2000-11-15     Open   M            52   \n",
      "3  Sergey Zhuravlev #1   0001 2000-02-27     Open   M            52   \n",
      "4        Hideaki Inaba   0001 2000-11-15     Open   M            52   \n",
      "\n",
      "   Best3SquatKg  Best3BenchKg  Best3DeadliftKg  \n",
      "0         270.0         170.0            140.0  \n",
      "1         270.0         170.0            140.0  \n",
      "2         222.5         112.5            215.0  \n",
      "3         222.5         112.5            215.0  \n",
      "4         225.0          90.0            220.0  \n"
     ]
    }
   ],
   "source": [
    "def load_federation_data(federation_path, federation_name):\n",
    "    \"\"\"\n",
    "    Load entries.csv and meet.csv files from all subfolders in a federation directory.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    federation_path : str\n",
    "        Path to the federation folder (e.g., \"../opl-data/meet-data/ipf\")\n",
    "    federation_name : str\n",
    "        Name of the federation (for display purposes)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    entries_list : list\n",
    "        List of entries dataframes\n",
    "    meets_list : list\n",
    "        List of meets dataframes\n",
    "    \"\"\"\n",
    "    # Get all folders in federation directory\n",
    "    folders = [f for f in os.listdir(federation_path) \n",
    "               if os.path.isdir(os.path.join(federation_path, f)) \n",
    "               and not f.startswith('.')]\n",
    "    \n",
    "    entries_list = []\n",
    "    meets_list = []\n",
    "    \n",
    "    for folder in folders:\n",
    "        entries_path = os.path.join(federation_path, folder, \"entries.csv\")\n",
    "        meet_path = os.path.join(federation_path, folder, \"meet.csv\")\n",
    "        \n",
    "        if os.path.exists(entries_path):\n",
    "            df_entries = pd.read_csv(entries_path)\n",
    "            df_entries['MeetID'] = folder\n",
    "            entries_list.append(df_entries)\n",
    "        \n",
    "        if os.path.exists(meet_path):\n",
    "            df_meet = pd.read_csv(meet_path)\n",
    "            df_meet['MeetID'] = folder\n",
    "            meets_list.append(df_meet)\n",
    "    \n",
    "    return entries_list, meets_list\n",
    "\n",
    "# Load data from all three federations\n",
    "ipf_path = \"../opl-data/meet-data/ipf\"\n",
    "usapl_path = \"../opl-data/meet-data/usapl\"\n",
    "pa_path = \"../opl-data/meet-data/pa\"\n",
    "\n",
    "# Load IPF data\n",
    "ipf_entries, ipf_meets = load_federation_data(ipf_path, \"IPF\")\n",
    "print(f\"IPF: Loaded {len(ipf_entries)} entries files, {len(ipf_meets)} meets files\")\n",
    "\n",
    "# Load USAPL data\n",
    "usapl_entries, usapl_meets = load_federation_data(usapl_path, \"USAPL\")\n",
    "print(f\"USAPL: Loaded {len(usapl_entries)} entries files, {len(usapl_meets)} meets files\")\n",
    "\n",
    "# Load PA data\n",
    "pa_entries, pa_meets = load_federation_data(pa_path, \"PA\")\n",
    "print(f\"PA: Loaded {len(pa_entries)} entries files, {len(pa_meets)} meets files\")\n",
    "\n",
    "# Combine all entries from all federations\n",
    "all_entries_list = ipf_entries + usapl_entries + pa_entries\n",
    "all_meets_list = ipf_meets + usapl_meets + pa_meets\n",
    "\n",
    "# Combine all entries\n",
    "df_entries_all = pd.concat(all_entries_list, ignore_index=True)\n",
    "\n",
    "# Combine all meets\n",
    "df_meets_all = pd.concat(all_meets_list, ignore_index=True)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"COMBINED RESULTS:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total entries: {len(df_entries_all)}\")\n",
    "print(f\"Total meets: {len(df_meets_all)}\")\n",
    "print(f\"\\nEntries breakdown:\")\n",
    "print(f\"  - IPF: {len(pd.concat(ipf_entries, ignore_index=True)) if ipf_entries else 0} entries\")\n",
    "print(f\"  - USAPL: {len(pd.concat(usapl_entries, ignore_index=True)) if usapl_entries else 0} entries\")\n",
    "print(f\"  - PA: {len(pd.concat(pa_entries, ignore_index=True)) if pa_entries else 0} entries\")\n",
    "print(f\"\\nMeets breakdown:\")\n",
    "print(f\"  - IPF: {len(pd.concat(ipf_meets, ignore_index=True)) if ipf_meets else 0} meets\")\n",
    "print(f\"  - USAPL: {len(pd.concat(usapl_meets, ignore_index=True)) if usapl_meets else 0} meets\")\n",
    "print(f\"  - PA: {len(pd.concat(pa_meets, ignore_index=True)) if pa_meets else 0} meets\")\n",
    "print(f\"\\nEntries dataframe shape: {df_entries_all.shape}\")\n",
    "print(f\"Meets dataframe shape: {df_meets_all.shape}\")\n",
    "\n",
    "# Merge entries with meet data using MeetID\n",
    "# This adds Date and other meet information to each entry\n",
    "df_entries_all = df_entries_all.merge(\n",
    "    df_meets_all,\n",
    "    on='MeetID',\n",
    "    how='left',  # Keep all entries even if meet data is missing\n",
    "    suffixes=('', '_meet')  # In case of duplicate column names\n",
    ")\n",
    "\n",
    "# Convert Date to datetime \n",
    "df_entries_all['Date'] = pd.to_datetime(df_entries_all['Date'])\n",
    "\n",
    "# Convert BirthDate to datetime \n",
    "df_entries_all['BirthDate'] = pd.to_datetime(df_entries_all['BirthDate'], errors='coerce')\n",
    "\n",
    "# Calculate age in years: (Date - BirthDate) / 365.25\n",
    "# Using 365.25 to account for leap years\n",
    "df_entries_all['Age'] = (df_entries_all['Date'] - df_entries_all['BirthDate']).dt.days / 365.25\n",
    "\n",
    "# For entries where BirthDate is missing but BirthYear exists, estimate age\n",
    "# Use mid-year as approximation: Date.year - BirthYear\n",
    "missing_age_mask = df_entries_all['Age'].isna() & df_entries_all['BirthYear'].notna()\n",
    "df_entries_all.loc[missing_age_mask, 'Age'] = (\n",
    "    df_entries_all.loc[missing_age_mask, 'Date'].dt.year - \n",
    "    df_entries_all.loc[missing_age_mask, 'BirthYear']\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Age still missing: {df_entries_all['Age'].isna().sum()}\")\n",
    "print(f\"\\nAge statistics:\")\n",
    "print(df_entries_all['Age'].describe())\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"AFTER MERGE:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Entries dataframe shape: {df_entries_all.shape}\")\n",
    "print(f\"Columns: {list(df_entries_all.columns)}\")\n",
    "print(f\"\\nDate column info:\")\n",
    "print(f\"  - Non-null dates: {df_entries_all['Date'].notna().sum()}\")\n",
    "print(f\"  - Date range: {df_entries_all['Date'].min()} to {df_entries_all['Date'].max()}\")\n",
    "print(\"\\nFirst few rows with merged data:\")\n",
    "print(df_entries_all[['Name', 'MeetID', 'Date', 'Division','Sex','WeightClassKg','Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adcd14fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 251 missing values in Best3SquatKg using Best3SquatLbs\n",
      "Filled 257 missing values in Best3BenchKg using Best3BenchLbs\n",
      "Filled 261 missing values in Best3DeadliftKg using Best3DeadliftLbs\n",
      "Filled 263 missing values in Squat1Kg using Squat1Lbs\n",
      "Filled 263 missing values in Squat2Kg using Squat2Lbs\n",
      "Filled 260 missing values in Squat3Kg using Squat3Lbs\n",
      "Filled 264 missing values in Bench1Kg using Bench1Lbs\n",
      "Filled 264 missing values in Bench2Kg using Bench2Lbs\n",
      "Filled 262 missing values in Bench3Kg using Bench3Lbs\n",
      "Filled 262 missing values in Deadlift1Kg using Deadlift1Lbs\n",
      "Filled 261 missing values in Deadlift2Kg using Deadlift2Lbs\n",
      "Filled 261 missing values in Deadlift3Kg using Deadlift3Lbs\n",
      "Filled 245 missing values in TotalKg using TotalLbs\n"
     ]
    }
   ],
   "source": [
    "# Convert any Lbs columns to Kg and fill missing Kg values\n",
    "# Conversion factor: 1 lb = 0.453592 kg\n",
    "\n",
    "# Define the mapping of Lbs columns to their corresponding Kg columns\n",
    "lbs_to_kg_mapping = {\n",
    "    'Best3SquatLbs': 'Best3SquatKg',\n",
    "    'Best3BenchLbs': 'Best3BenchKg',\n",
    "    'Best3DeadliftLbs': 'Best3DeadliftKg',\n",
    "    'Squat1Lbs': 'Squat1Kg',\n",
    "    'Squat2Lbs': 'Squat2Kg',\n",
    "    'Squat3Lbs': 'Squat3Kg',\n",
    "    'Bench1Lbs': 'Bench1Kg',\n",
    "    'Bench2Lbs': 'Bench2Kg',\n",
    "    'Bench3Lbs': 'Bench3Kg',\n",
    "    'Deadlift1Lbs': 'Deadlift1Kg',\n",
    "    'Deadlift2Lbs': 'Deadlift2Kg',\n",
    "    'Deadlift3Lbs': 'Deadlift3Kg',\n",
    "    'TotalLbs': 'TotalKg'\n",
    "}\n",
    "\n",
    "# Convert and fill missing values\n",
    "for lbs_col, kg_col in lbs_to_kg_mapping.items():\n",
    "    if lbs_col in df_entries_all.columns:\n",
    "        # Convert lbs to kg (multiply by 0.453592)\n",
    "        converted_values = df_entries_all[lbs_col] * 0.453592\n",
    "        \n",
    "        # Fill missing Kg values with converted Lbs values (only where Kg is missing and Lbs exists)\n",
    "        mask = df_entries_all[kg_col].isna() & df_entries_all[lbs_col].notna()\n",
    "        df_entries_all.loc[mask, kg_col] = converted_values[mask]\n",
    "        \n",
    "        print(f\"Filled {mask.sum()} missing values in {kg_col} using {lbs_col}\")\n",
    "# Drop all Lbs columns after conversion\n",
    "lbs_columns_to_drop = [col for col in df_entries_all.columns if col.endswith('Lbs')]\n",
    "df_entries_all = df_entries_all.drop(columns=lbs_columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1326911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created LifterID using columns: ['Name', 'Sex', 'BirthYear']\n",
      "   LifterID                 Name Sex  BirthYear\n",
      "0      9746    Andrzej Stanaszek   M     1971.0\n",
      "1      9746    Andrzej Stanaszek   M     1971.0\n",
      "2    118950  Sergey Zhuravlev #1   M     1960.0\n",
      "3    118950  Sergey Zhuravlev #1   M     1960.0\n",
      "4     52278        Hideaki Inaba   M     1944.0\n",
      "5     52278        Hideaki Inaba   M     1944.0\n",
      "6     43877      Ervin Gainer Sr   M     1966.0\n",
      "7     43877      Ervin Gainer Sr   M     1966.0\n",
      "8     25867      Chih-Chiang Hsu   M     1979.0\n",
      "9     25867      Chih-Chiang Hsu   M     1979.0\n"
     ]
    }
   ],
   "source": [
    "# Create a surrogate LifterID so we can build per-lifter competition histories\n",
    "# We use a combination of fairly stable identity columns.\n",
    "\n",
    "id_cols = [col for col in ['Name', 'Sex', 'BirthYear'] if col in df_entries_all.columns]\n",
    "\n",
    "if id_cols:\n",
    "    # Build a string key from available identity columns\n",
    "    lifter_key = df_entries_all[id_cols].astype(str).agg('|'.join, axis=1)\n",
    "\n",
    "    # Turn the key into an integer LifterID (stable within this run)\n",
    "    df_entries_all['LifterID'] = lifter_key.astype('category').cat.codes\n",
    "\n",
    "    print(\"Created LifterID using columns:\", id_cols)\n",
    "    print(df_entries_all[['LifterID'] + id_cols].head(10))\n",
    "else:\n",
    "    raise ValueError(\"No suitable columns found to construct LifterID.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6073aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-lifter competition history created using 'LifterID' and 'Date'.\n",
      "        LifterID       Date  CompIndex\n",
      "378269         0 2002-01-01          1\n",
      "378268         0 2002-05-29          2\n",
      "378307         1 2002-01-01          1\n",
      "378306         1 2002-05-29          2\n",
      "378635         2 2002-01-01          1\n",
      "378634         2 2002-05-29          2\n",
      "5593           3 2002-02-16          1\n",
      "5592           3 2002-09-25          2\n",
      "405617         4 2023-11-13          1\n",
      "405618         4 2023-12-17          2\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Group by LifterID and sort competitions chronologically\n",
    "# This creates a competition history for each lifter.\n",
    "\n",
    "# Sort by lifter and date so each lifter's rows are in chronological order\n",
    "df_entries_all = df_entries_all.sort_values(['LifterID', 'Date'])\n",
    "\n",
    "# Create an explicit competition index per lifter (1 = first recorded meet, 2 = second, ...)\n",
    "df_entries_all['CompIndex'] = df_entries_all.groupby('LifterID').cumcount() + 1\n",
    "\n",
    "print(\"Per-lifter competition history created using 'LifterID' and 'Date'.\")\n",
    "print(df_entries_all[['LifterID', 'Date', 'CompIndex']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0cd2a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows before filtering by competition count: 233466\n",
      "Total rows after keeping lifters with >= 2 competitions: 232354\n",
      "Number of unique lifters remaining: 61962\n",
      "After filtering to SBD events: 232354 rows (dropped 0)\n",
      "After filtering to Raw equipment: 232354 rows (dropped 0)\n",
      "Number of unique lifters remaining: 61962\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Filter valid lifters\n",
    "# - Keep only lifters with at least 2 competitions\n",
    "# - Optionally filter by other criteria (e.g., only SBD events, only Raw equipment)\n",
    "\n",
    "# Count number of competitions per lifter\n",
    "comp_counts = df_entries_all.groupby('LifterID')['CompIndex'].max().rename('NumComps')\n",
    "\n",
    "df_entries_all = df_entries_all.merge(comp_counts, on='LifterID', how='left')\n",
    "\n",
    "# Keep only lifters with at least 2 competitions\n",
    "min_comps = 2\n",
    "valid_mask = df_entries_all['NumComps'] >= min_comps\n",
    "\n",
    "print(f\"Total rows before filtering by competition count: {len(df_entries_all)}\")\n",
    "df_entries_all = df_entries_all[valid_mask].copy()\n",
    "print(f\"Total rows after keeping lifters with >= {min_comps} competitions: {len(df_entries_all)}\")\n",
    "print(f\"Number of unique lifters remaining: {df_entries_all['LifterID'].nunique()}\")\n",
    "\n",
    "# Optional: filter to SBD + Raw if those columns exist\n",
    "if 'Event' in df_entries_all.columns:\n",
    "    before = len(df_entries_all)\n",
    "    df_entries_all = df_entries_all[df_entries_all['Event'] == 'SBD']\n",
    "    print(f\"After filtering to SBD events: {len(df_entries_all)} rows (dropped {before - len(df_entries_all)})\")\n",
    "\n",
    "if 'Equipment' in df_entries_all.columns:\n",
    "    before = len(df_entries_all)\n",
    "    df_entries_all = df_entries_all[df_entries_all['Equipment'] == 'Raw']\n",
    "    print(f\"After filtering to Raw equipment: {len(df_entries_all)} rows (dropped {before - len(df_entries_all)})\")\n",
    "\n",
    "print(f\"Number of unique lifters remaining: {df_entries_all['LifterID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d5f3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "# NOTE: Date is preserved for time-based features in Step 3\n",
    "columns_to_drop = ['Name', 'Bench1Kg', 'KoreanName', 'ChineseName', 'Bench2Kg', 'Bench3Kg', 'BirthDate', 'Squat1Kg', 'Squat2Kg', 'Squat3Kg', \n",
    "                    'Deadlift1Kg', 'Deadlift2Kg', 'Deadlift3Kg', 'Country', 'BirthYear', 'BodyweightKg', 'Place', 'Event', 'Equipment',\n",
    "                    'Deadlift4Kg', 'Bench4Kg', 'Squat4Kg', 'Team', 'MeetID', 'State', 'AgeRange', 'Tested', 'DeadliftEquipment', 'CyrillicName', 'MeetCountry', 'MeetState', 'MeetTown', 'MeetName', 'Federation']\n",
    "df_cleaned = df_entries_all.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1789f5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL CLEANED AND FILTERED DATAFRAME:\n",
      "============================================================\n",
      "\n",
      "Cleaned DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 232354 entries, 0 to 233465\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   Division         232352 non-null  object        \n",
      " 1   WeightClassKg    228461 non-null  object        \n",
      " 2   Best3SquatKg     228835 non-null  float64       \n",
      " 3   Best3BenchKg     228771 non-null  float64       \n",
      " 4   Best3DeadliftKg  229390 non-null  float64       \n",
      " 5   TotalKg          224096 non-null  float64       \n",
      " 6   Sex              232354 non-null  object        \n",
      " 7   Age              228140 non-null  float64       \n",
      " 8   Date             232354 non-null  datetime64[ns]\n",
      " 9   LifterID         232354 non-null  int32         \n",
      " 10  CompIndex        232354 non-null  int64         \n",
      " 11  NumComps_x       232354 non-null  int64         \n",
      " 12  NumComps_y       232354 non-null  int64         \n",
      " 13  NumComps         232354 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int32(1), int64(4), object(3)\n",
      "memory usage: 25.7+ MB\n",
      "None\n",
      "\n",
      "First few rows of cleaned data:\n",
      "  Division WeightClassKg  Best3SquatKg  Best3BenchKg  Best3DeadliftKg  \\\n",
      "0     Open          120+         375.0           NaN              NaN   \n",
      "1     Open          120+         375.0           NaN              NaN   \n",
      "2     MR-C            56         182.5         105.0            185.0   \n",
      "3     MR-C            56         190.0         112.5            197.5   \n",
      "4     MR-C            56         196.5         117.5            212.5   \n",
      "5    MR-Jr            93         245.0         165.0            257.5   \n",
      "6     MR-O            93         272.5         155.0            280.0   \n",
      "7     MR-O           105         287.5         195.0            275.0   \n",
      "8    FR-HS          67.5         133.8          61.2            154.2   \n",
      "9    MR-Jr           125         260.0         170.0            260.0   \n",
      "\n",
      "   TotalKg Sex        Age       Date  LifterID  CompIndex  NumComps_x  \\\n",
      "0      NaN   M  35.865845 2023-11-13         4          1           4   \n",
      "1      NaN   M  35.958932 2023-12-17         4          2           4   \n",
      "2    472.5   M  18.000000 2024-11-09         9          1           3   \n",
      "3    500.0   M  19.000000 2025-02-08         9          2           3   \n",
      "4    526.5   M  19.000000 2025-04-03         9          3           3   \n",
      "5    667.5   M  22.000000 2015-03-21        13          1           4   \n",
      "6    707.5   M  23.000000 2016-06-04        13          2           4   \n",
      "7    757.5   M  24.000000 2017-04-08        13          4           4   \n",
      "8    349.2   F  17.000000 2024-05-18        14          2           2   \n",
      "9    690.0   M  23.000000 2023-09-09        15          1           4   \n",
      "\n",
      "   NumComps_y  NumComps  \n",
      "0           2         2  \n",
      "1           2         2  \n",
      "2           3         3  \n",
      "3           3         3  \n",
      "4           3         3  \n",
      "5           4         4  \n",
      "6           4         4  \n",
      "7           4         4  \n",
      "8           2         2  \n",
      "9           4         4  \n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned and filtered dataframe\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL CLEANED AND FILTERED DATAFRAME:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nCleaned DataFrame Info:\")\n",
    "print(df_cleaned.info())\n",
    "\n",
    "print(\"\\nFirst few rows of cleaned data:\")\n",
    "print(df_cleaned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "703fdbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined.\n",
      "Ready to create training examples...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create Training Examples (Sliding Window Approach)\n",
    "# For each lifter with N competitions, create N-1 training examples\n",
    "# Each example uses previous competitions to predict the next competition's lifts\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def extract_historical_features(previous_comps):\n",
    "    \"\"\"\n",
    "    Extract historical performance features from previous competitions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    previous_comps : DataFrame\n",
    "        DataFrame containing all previous competitions for a lifter\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of historical features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Previous lifts (last competition)\n",
    "    if len(previous_comps) > 0:\n",
    "        last_comp = previous_comps.iloc[-1]\n",
    "        features['PrevBest3SquatKg'] = last_comp.get('Best3SquatKg', np.nan)\n",
    "        features['PrevBest3BenchKg'] = last_comp.get('Best3BenchKg', np.nan)\n",
    "        features['PrevBest3DeadliftKg'] = last_comp.get('Best3DeadliftKg', np.nan)\n",
    "        features['PrevTotalKg'] = last_comp.get('TotalKg', np.nan)\n",
    "    else:\n",
    "        features['PrevBest3SquatKg'] = np.nan\n",
    "        features['PrevBest3BenchKg'] = np.nan\n",
    "        features['PrevBest3DeadliftKg'] = np.nan\n",
    "        features['PrevTotalKg'] = np.nan\n",
    "    \n",
    "    # All-time PRs from previous competitions\n",
    "    valid_squat = previous_comps['Best3SquatKg'].dropna()\n",
    "    valid_bench = previous_comps['Best3BenchKg'].dropna()\n",
    "    valid_deadlift = previous_comps['Best3DeadliftKg'].dropna()\n",
    "    valid_total = previous_comps['TotalKg'].dropna()\n",
    "    \n",
    "    features['PRBest3SquatKg'] = valid_squat.max() if len(valid_squat) > 0 else np.nan\n",
    "    features['PRBest3BenchKg'] = valid_bench.max() if len(valid_bench) > 0 else np.nan\n",
    "    features['PRBest3DeadliftKg'] = valid_deadlift.max() if len(valid_deadlift) > 0 else np.nan\n",
    "    features['PRTotalKg'] = valid_total.max() if len(valid_total) > 0 else np.nan\n",
    "    \n",
    "    # Averages of last 3 competitions (or all if fewer than 3)\n",
    "    n_recent = min(3, len(previous_comps))\n",
    "    if n_recent > 0:\n",
    "        recent_comps = previous_comps.tail(n_recent)\n",
    "        features['AvgBest3SquatKg_Last3'] = recent_comps['Best3SquatKg'].mean()\n",
    "        features['AvgBest3BenchKg_Last3'] = recent_comps['Best3BenchKg'].mean()\n",
    "        features['AvgBest3DeadliftKg_Last3'] = recent_comps['Best3DeadliftKg'].mean()\n",
    "        features['AvgTotalKg_Last3'] = recent_comps['TotalKg'].mean()\n",
    "    else:\n",
    "        features['AvgBest3SquatKg_Last3'] = np.nan\n",
    "        features['AvgBest3BenchKg_Last3'] = np.nan\n",
    "        features['AvgBest3DeadliftKg_Last3'] = np.nan\n",
    "        features['AvgTotalKg_Last3'] = np.nan\n",
    "    \n",
    "    # Consistency (standard deviation) across all previous competitions\n",
    "    features['StdBest3SquatKg'] = valid_squat.std() if len(valid_squat) > 1 else np.nan\n",
    "    features['StdBest3BenchKg'] = valid_bench.std() if len(valid_bench) > 1 else np.nan\n",
    "    features['StdBest3DeadliftKg'] = valid_deadlift.std() if len(valid_deadlift) > 1 else np.nan\n",
    "    features['StdTotalKg'] = valid_total.std() if len(valid_total) > 1 else np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_time_features(current_comp, previous_comps, dates):\n",
    "    \"\"\"\n",
    "    Extract time-based features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    current_comp : Series\n",
    "        Current competition row\n",
    "    previous_comps : DataFrame\n",
    "        Previous competitions\n",
    "    dates : Series\n",
    "        Dates for all competitions (current + previous)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of time-based features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Competition count (which competition number this is)\n",
    "    features['CompIndex'] = current_comp.get('CompIndex', np.nan)\n",
    "    \n",
    "    # Age at current competition\n",
    "    features['Age'] = current_comp.get('Age', np.nan)\n",
    "    \n",
    "    # Days since last competition\n",
    "    if len(previous_comps) > 0 and 'Date' in current_comp and pd.notna(current_comp['Date']):\n",
    "        last_date = previous_comps.iloc[-1].get('Date')\n",
    "        if pd.notna(last_date):\n",
    "            days_diff = (current_comp['Date'] - last_date).days\n",
    "            features['DaysSinceLastComp'] = days_diff\n",
    "        else:\n",
    "            features['DaysSinceLastComp'] = np.nan\n",
    "    else:\n",
    "        features['DaysSinceLastComp'] = np.nan\n",
    "    \n",
    "    # Average days between competitions (for this lifter)\n",
    "    if len(previous_comps) > 0 and 'Date' in previous_comps.columns:\n",
    "        valid_dates = previous_comps['Date'].dropna()\n",
    "        if len(valid_dates) > 1:\n",
    "            date_diffs = valid_dates.diff().dropna()\n",
    "            features['AvgDaysBetweenComps'] = date_diffs.dt.days.mean() if len(date_diffs) > 0 else np.nan\n",
    "        else:\n",
    "            features['AvgDaysBetweenComps'] = np.nan\n",
    "    else:\n",
    "        features['AvgDaysBetweenComps'] = np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_context_features(current_comp):\n",
    "    \"\"\"\n",
    "    Extract context features from current competition.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    current_comp : Series\n",
    "        Current competition row\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of context features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Weight class (keep as string for now, can encode later)\n",
    "    features['WeightClassKg'] = current_comp.get('WeightClassKg', np.nan)\n",
    "    \n",
    "    # Sex (M/F)\n",
    "    features['Sex'] = current_comp.get('Sex', np.nan)\n",
    "    \n",
    "    # Division (Open, Junior, etc.)\n",
    "    features['Division'] = current_comp.get('Division', np.nan)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_trend_features(all_previous_comps):\n",
    "    \"\"\"\n",
    "    Extract trend/improvement features from all previous competitions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    all_previous_comps : DataFrame\n",
    "        All previous competitions sorted by CompIndex\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of trend features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    if len(all_previous_comps) == 0:\n",
    "        # No previous competitions\n",
    "        features['SquatImprovementRate'] = np.nan\n",
    "        features['BenchImprovementRate'] = np.nan\n",
    "        features['DeadliftImprovementRate'] = np.nan\n",
    "        features['SquatImprovementDirection'] = 0\n",
    "        features['BenchImprovementDirection'] = 0\n",
    "        features['DeadliftImprovementDirection'] = 0\n",
    "        features['CompsSincePRSquat'] = np.nan\n",
    "        features['CompsSincePRBench'] = np.nan\n",
    "        features['CompsSincePRDeadlift'] = np.nan\n",
    "        return features\n",
    "    \n",
    "    # Improvement rate (slope) - change per competition\n",
    "    valid_comps = all_previous_comps.dropna(subset=['Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg'], how='all')\n",
    "    \n",
    "    if len(valid_comps) >= 2:\n",
    "        # Calculate slope using linear regression (simple: (last - first) / (n_comps - 1))\n",
    "        comp_indices = valid_comps['CompIndex'].values\n",
    "        squat_values = valid_comps['Best3SquatKg'].values\n",
    "        bench_values = valid_comps['Best3BenchKg'].values\n",
    "        deadlift_values = valid_comps['Best3DeadliftKg'].values\n",
    "        \n",
    "        # Squat improvement rate\n",
    "        if len(squat_values[~np.isnan(squat_values)]) >= 2:\n",
    "            valid_squat = ~np.isnan(squat_values)\n",
    "            if valid_squat.sum() >= 2:\n",
    "                valid_indices = comp_indices[valid_squat]\n",
    "                valid_squat_vals = squat_values[valid_squat]\n",
    "                if len(valid_indices) > 1:\n",
    "                    features['SquatImprovementRate'] = (valid_squat_vals[-1] - valid_squat_vals[0]) / (valid_indices[-1] - valid_indices[0])\n",
    "                else:\n",
    "                    features['SquatImprovementRate'] = np.nan\n",
    "            else:\n",
    "                features['SquatImprovementRate'] = np.nan\n",
    "        else:\n",
    "            features['SquatImprovementRate'] = np.nan\n",
    "        \n",
    "        # Bench improvement rate\n",
    "        if len(bench_values[~np.isnan(bench_values)]) >= 2:\n",
    "            valid_bench = ~np.isnan(bench_values)\n",
    "            if valid_bench.sum() >= 2:\n",
    "                valid_indices = comp_indices[valid_bench]\n",
    "                valid_bench_vals = bench_values[valid_bench]\n",
    "                if len(valid_indices) > 1:\n",
    "                    features['BenchImprovementRate'] = (valid_bench_vals[-1] - valid_bench_vals[0]) / (valid_indices[-1] - valid_indices[0])\n",
    "                else:\n",
    "                    features['BenchImprovementRate'] = np.nan\n",
    "            else:\n",
    "                features['BenchImprovementRate'] = np.nan\n",
    "        else:\n",
    "            features['BenchImprovementRate'] = np.nan\n",
    "        \n",
    "        # Deadlift improvement rate\n",
    "        if len(deadlift_values[~np.isnan(deadlift_values)]) >= 2:\n",
    "            valid_deadlift = ~np.isnan(deadlift_values)\n",
    "            if valid_deadlift.sum() >= 2:\n",
    "                valid_indices = comp_indices[valid_deadlift]\n",
    "                valid_deadlift_vals = deadlift_values[valid_deadlift]\n",
    "                if len(valid_indices) > 1:\n",
    "                    features['DeadliftImprovementRate'] = (valid_deadlift_vals[-1] - valid_deadlift_vals[0]) / (valid_indices[-1] - valid_indices[0])\n",
    "                else:\n",
    "                    features['DeadliftImprovementRate'] = np.nan\n",
    "            else:\n",
    "                features['DeadliftImprovementRate'] = np.nan\n",
    "        else:\n",
    "            features['DeadliftImprovementRate'] = np.nan\n",
    "        \n",
    "        # Improvement direction (comparing last 2 competitions)\n",
    "        if len(valid_comps) >= 2:\n",
    "            last_two = valid_comps.tail(2)\n",
    "            last_squat = last_two.iloc[-1]['Best3SquatKg']\n",
    "            prev_squat = last_two.iloc[-2]['Best3SquatKg']\n",
    "            if pd.notna(last_squat) and pd.notna(prev_squat):\n",
    "                features['SquatImprovementDirection'] = 1 if last_squat > prev_squat else (-1 if last_squat < prev_squat else 0)\n",
    "            else:\n",
    "                features['SquatImprovementDirection'] = 0\n",
    "            \n",
    "            last_bench = last_two.iloc[-1]['Best3BenchKg']\n",
    "            prev_bench = last_two.iloc[-2]['Best3BenchKg']\n",
    "            if pd.notna(last_bench) and pd.notna(prev_bench):\n",
    "                features['BenchImprovementDirection'] = 1 if last_bench > prev_bench else (-1 if last_bench < prev_bench else 0)\n",
    "            else:\n",
    "                features['BenchImprovementDirection'] = 0\n",
    "            \n",
    "            last_deadlift = last_two.iloc[-1]['Best3DeadliftKg']\n",
    "            prev_deadlift = last_two.iloc[-2]['Best3DeadliftKg']\n",
    "            if pd.notna(last_deadlift) and pd.notna(prev_deadlift):\n",
    "                features['DeadliftImprovementDirection'] = 1 if last_deadlift > prev_deadlift else (-1 if last_deadlift < prev_deadlift else 0)\n",
    "            else:\n",
    "                features['DeadliftImprovementDirection'] = 0\n",
    "        else:\n",
    "            features['SquatImprovementDirection'] = 0\n",
    "            features['BenchImprovementDirection'] = 0\n",
    "            features['DeadliftImprovementDirection'] = 0\n",
    "        \n",
    "        # Comps since PR (number of competitions since achieving personal record)\n",
    "        pr_squat = all_previous_comps['Best3SquatKg'].max()\n",
    "        pr_bench = all_previous_comps['Best3BenchKg'].max()\n",
    "        pr_deadlift = all_previous_comps['Best3DeadliftKg'].max()\n",
    "        \n",
    "        if pd.notna(pr_squat):\n",
    "            pr_squat_comps = all_previous_comps[all_previous_comps['Best3SquatKg'] == pr_squat]\n",
    "            if len(pr_squat_comps) > 0:\n",
    "                last_pr_comp = pr_squat_comps['CompIndex'].max()\n",
    "                last_comp = all_previous_comps['CompIndex'].max()\n",
    "                features['CompsSincePRSquat'] = last_comp - last_pr_comp\n",
    "            else:\n",
    "                features['CompsSincePRSquat'] = np.nan\n",
    "        else:\n",
    "            features['CompsSincePRSquat'] = np.nan\n",
    "        \n",
    "        if pd.notna(pr_bench):\n",
    "            pr_bench_comps = all_previous_comps[all_previous_comps['Best3BenchKg'] == pr_bench]\n",
    "            if len(pr_bench_comps) > 0:\n",
    "                last_pr_comp = pr_bench_comps['CompIndex'].max()\n",
    "                last_comp = all_previous_comps['CompIndex'].max()\n",
    "                features['CompsSincePRBench'] = last_comp - last_pr_comp\n",
    "            else:\n",
    "                features['CompsSincePRBench'] = np.nan\n",
    "        else:\n",
    "            features['CompsSincePRBench'] = np.nan\n",
    "        \n",
    "        if pd.notna(pr_deadlift):\n",
    "            pr_deadlift_comps = all_previous_comps[all_previous_comps['Best3DeadliftKg'] == pr_deadlift]\n",
    "            if len(pr_deadlift_comps) > 0:\n",
    "                last_pr_comp = pr_deadlift_comps['CompIndex'].max()\n",
    "                last_comp = all_previous_comps['CompIndex'].max()\n",
    "                features['CompsSincePRDeadlift'] = last_comp - last_pr_comp\n",
    "            else:\n",
    "                features['CompsSincePRDeadlift'] = np.nan\n",
    "        else:\n",
    "            features['CompsSincePRDeadlift'] = np.nan\n",
    "    else:\n",
    "        # Not enough competitions for trend analysis\n",
    "        features['SquatImprovementRate'] = np.nan\n",
    "        features['BenchImprovementRate'] = np.nan\n",
    "        features['DeadliftImprovementRate'] = np.nan\n",
    "        features['SquatImprovementDirection'] = 0\n",
    "        features['BenchImprovementDirection'] = 0\n",
    "        features['DeadliftImprovementDirection'] = 0\n",
    "        features['CompsSincePRSquat'] = np.nan\n",
    "        features['CompsSincePRBench'] = np.nan\n",
    "        features['CompsSincePRDeadlift'] = np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "def create_training_examples(df):\n",
    "    \"\"\"\n",
    "    Create training examples using sliding window approach.\n",
    "    \n",
    "    For each lifter with N competitions, creates N-1 training examples:\n",
    "    - Example 1: Use comp 1 → predict comp 2\n",
    "    - Example 2: Use comps 1-2 → predict comp 3\n",
    "    - Example 3: Use comps 1-3 → predict comp 4\n",
    "    - etc.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame with per-lifter competition histories (sorted by LifterID and Date)\n",
    "        Must have columns: LifterID, CompIndex, Date, and lift columns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df_training : DataFrame\n",
    "        DataFrame with features (X) and targets (y) for training\n",
    "    \"\"\"\n",
    "    training_examples = []\n",
    "    \n",
    "    # Group by LifterID\n",
    "    for lifter_id, lifter_group in df.groupby('LifterID'):\n",
    "        # Sort by CompIndex to ensure chronological order\n",
    "        lifter_group = lifter_group.sort_values('CompIndex').reset_index(drop=True)\n",
    "        \n",
    "        # For each competition from 2nd onwards (we need at least 1 previous comp)\n",
    "        for idx in range(1, len(lifter_group)):\n",
    "            current_comp = lifter_group.iloc[idx]\n",
    "            previous_comps = lifter_group.iloc[:idx]  # All competitions before current\n",
    "            \n",
    "            # Extract all features\n",
    "            example = {}\n",
    "            \n",
    "            # Metadata\n",
    "            example['LifterID'] = lifter_id\n",
    "            example['CompIndex'] = current_comp['CompIndex']\n",
    "            \n",
    "            # Historical features\n",
    "            hist_features = extract_historical_features(previous_comps)\n",
    "            example.update(hist_features)\n",
    "            \n",
    "            # Time-based features\n",
    "            time_features = extract_time_features(current_comp, previous_comps, lifter_group['Date'])\n",
    "            example.update(time_features)\n",
    "            \n",
    "            # Context features\n",
    "            context_features = extract_context_features(current_comp)\n",
    "            example.update(context_features)\n",
    "            \n",
    "            # Trend features\n",
    "            trend_features = extract_trend_features(previous_comps)\n",
    "            example.update(trend_features)\n",
    "            \n",
    "            # Target variables (what we're trying to predict)\n",
    "            example['NextBest3SquatKg'] = current_comp.get('Best3SquatKg', np.nan)\n",
    "            example['NextBest3BenchKg'] = current_comp.get('Best3BenchKg', np.nan)\n",
    "            example['NextBest3DeadliftKg'] = current_comp.get('Best3DeadliftKg', np.nan)\n",
    "            \n",
    "            training_examples.append(example)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_training = pd.DataFrame(training_examples)\n",
    "    \n",
    "    return df_training\n",
    "\n",
    "print(\"Feature extraction functions defined.\")\n",
    "print(\"Ready to create training examples...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
