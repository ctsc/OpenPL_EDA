{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Aggregation\n",
    "\n",
    "This notebook loads and aggregates all meet data from the OpenPowerlifting dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data loading...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Import utils directly (since we're in the eda directory)\n",
    "from utils import load_all_meets, merge_entries_meets, clean_data\n",
    "\n",
    "print(\"Starting data loading...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from 2015-2025 (this may take several minutes)...\n",
      "Tip: If this crashes, restart and set max_federations=50 in the function call below\n",
      "Date filter enabled: 2015-01-01 to 2025-12-31\n",
      "Found 426 federation directories\n",
      "\n",
      "================================================================================\n",
      "PASS 1: Loading meets and filtering by date range...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading meets (pass 1): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [01:18<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Pass 1 complete:\n",
      "  Total meets found: 53,985\n",
      "  Meets in date range (2015-01-01 to 2025-12-31): 38,880\n",
      "  Meets filtered out: 15,105\n",
      "\n",
      "================================================================================\n",
      "PASS 2: Loading entries for filtered meets...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading entries (pass 2): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [03:06<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining 72 entry chunks...\n",
      "✓ Loaded 2,545,338 entries from 2,545,338 total rows\n",
      "  (Only entries for meets in date range 2015-01-01 to 2025-12-31)\n",
      "\n",
      "Combining 38880 meet records...\n",
      "✓ Loaded 38,880 meets\n",
      "  (Only meets in date range 2015-01-01 to 2025-12-31)\n",
      "\n",
      "✓ Successfully loaded 2,545,338 entries\n",
      "  Memory: 3358.1 MB\n",
      "✓ Successfully loaded 38,880 meets\n",
      "  Memory: 17.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Load entries and meets from last 10 years (2015-2025)\n",
    "# Filtering happens during loading to avoid loading all 3.5M entries into memory\n",
    "# Use max_federations parameter to limit for testing (e.g., max_federations=50)\n",
    "# Set to None to load all federations (may take 10-20 minutes and use significant memory)\n",
    "\n",
    "print(\"Loading data from 2015-2025 (this may take several minutes)...\")\n",
    "print(\"Tip: If this crashes, restart and set max_federations=50 in the function call below\")\n",
    "\n",
    "# Initialize variables\n",
    "entries_df = None\n",
    "meets_df = None\n",
    "\n",
    "try:\n",
    "    # Load data - filtering to 2015-2025 happens during load\n",
    "    entries_df, meets_df = load_all_meets(\n",
    "        base_path=\"../opl-data/meet-data\",\n",
    "        max_federations=None,  # Set to 50 for testing, None for all federations\n",
    "        chunk_size=100,  # Process in chunks to save memory\n",
    "        date_range=('2015-01-01', '2025-12-31')  # Only load meets from 2015-2025\n",
    "    )\n",
    "    \n",
    "    # Verify dataframes are defined\n",
    "    if entries_df is not None and len(entries_df) > 0:\n",
    "        print(f\"\\n✓ Successfully loaded {len(entries_df):,} entries\")\n",
    "        print(f\"  Memory: {entries_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    else:\n",
    "        print(\"⚠ Warning: entries_df is empty or None\")\n",
    "        entries_df = pd.DataFrame()  # Ensure it's defined\n",
    "        \n",
    "    if meets_df is not None and len(meets_df) > 0:\n",
    "        print(f\"✓ Successfully loaded {len(meets_df):,} meets\")\n",
    "        print(f\"  Memory: {meets_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    else:\n",
    "        print(\"⚠ Warning: meets_df is empty or None\")\n",
    "        meets_df = pd.DataFrame()  # Ensure it's defined\n",
    "        \n",
    "except MemoryError:\n",
    "    print(\"❌ Out of memory! Try loading fewer federations:\")\n",
    "    print(\"   Change max_federations=None to max_federations=50\")\n",
    "    entries_df = pd.DataFrame()\n",
    "    meets_df = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading data: {e}\")\n",
    "    print(\"   Dataframes initialized as empty - check error above\")\n",
    "    entries_df = pd.DataFrame()\n",
    "    meets_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Merged dataset: 2,545,338 rows\n",
      "\n",
      "Merged dataset shape: (2545338, 71)\n"
     ]
    }
   ],
   "source": [
    "# Merge entries with meet data\n",
    "merged_df = merge_entries_meets(entries_df, meets_df)\n",
    "print(f\"\\nMerged dataset shape: {merged_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Data already filtered to 2015-2025 during loading\n",
      "Merged dataset shape: (2545338, 71)\n"
     ]
    }
   ],
   "source": [
    "# Date filtering is now done during loading (see Cell 2)\n",
    "# No separate filtering step needed - data is already filtered to 2015-2025\n",
    "print(f\"\\n✓ Data already filtered to 2015-2025 during loading\")\n",
    "print(f\"Merged dataset shape: {merged_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset shape: (2545338, 73)\n",
      "\n",
      "Columns: ['Name', 'WeightClassKg', 'Sex', 'Age', 'Division', 'Event', 'BodyweightKg', 'Equipment', 'Squat1Kg', 'Squat2Kg', 'Squat3Kg', 'Best3SquatKg', 'Squat4Kg', 'Bench1Kg', 'Bench2Kg', 'Bench3Kg', 'Best3BenchKg', 'Bench4Kg', 'Deadlift1Kg', 'Deadlift2Kg', 'Deadlift3Kg', 'Best3DeadliftKg', 'Deadlift4Kg', 'TotalKg', 'Place', 'Federation', 'MeetPath', 'Team', 'Tested', 'Country', 'BirthDate', 'State', 'EntryDate', 'BodyweightLbs', 'WeightClassLbs', 'Deadlift1Lbs', 'Deadlift2Lbs', 'Deadlift3Lbs', 'Deadlift4Lbs', 'Best3DeadliftLbs', 'TotalLbs', 'BirthYear', 'Squat1Lbs', 'Squat2Lbs', 'Squat3Lbs', 'Best3SquatLbs', 'Bench1Lbs', 'Bench2Lbs', 'Bench3Lbs', 'Best3BenchLbs', 'Bench4Lbs', 'Squat4Lbs', 'CyrillicName', 'AgeRange', 'ChineseName', 'College/University', 'GreekName', 'SquatEquipment', 'DeadliftEquipment', 'BenchEquipment', 'JapaneseName', 'KoreanName', 'School', 'Federation_meet', 'Date', 'MeetCountry', 'MeetState', 'MeetTown', 'MeetName', 'RuleSet', 'Sanctioned', 'MeetDate', 'WeightClassKg_numeric']\n"
     ]
    }
   ],
   "source": [
    "# Clean and prepare data\n",
    "df = clean_data(merged_df)\n",
    "print(f\"Cleaned dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data for parquet save...\n",
      "  Converting 34 object columns to string...\n",
      "\n",
      "Saving to ..\\data\\processed\\full_dataset.parquet...\n",
      "  This may take a few minutes for large datasets...\n",
      "✓ Saved dataset successfully!\n",
      "  Size: 2,545,338 rows, 73 columns\n",
      "  File size: 66.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Save to parquet for faster loading later\n",
    "if df is not None and len(df) > 0:\n",
    "    try:\n",
    "        output_path = Path(\"../data/processed/full_dataset.parquet\")\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Fix object columns that cause ArrowTypeError\n",
    "        # Convert all object columns to string for parquet compatibility\n",
    "        print(\"\\nPreparing data for parquet save...\")\n",
    "        df_to_save = df.copy()\n",
    "        \n",
    "        # Convert all object columns to string\n",
    "        object_cols = df_to_save.select_dtypes(include=['object']).columns\n",
    "        print(f\"  Converting {len(object_cols)} object columns to string...\")\n",
    "        for col in object_cols:\n",
    "            # Convert to string, handling NaN values\n",
    "            df_to_save[col] = df_to_save[col].astype(str)\n",
    "            # Replace 'nan' strings with empty string for cleaner data\n",
    "            df_to_save[col] = df_to_save[col].replace('nan', '')\n",
    "        \n",
    "        print(f\"\\nSaving to {output_path}...\")\n",
    "        print(f\"  This may take a few minutes for large datasets...\")\n",
    "        df_to_save.to_parquet(output_path, compression='snappy', index=False, engine='pyarrow')\n",
    "        print(f\"✓ Saved dataset successfully!\")\n",
    "        print(f\"  Size: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "        print(f\"  File size: {output_path.stat().st_size / 1024**2:.1f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving data: {e}\")\n",
    "        print(f\"  Error type: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        print(f\"  Details: {traceback.format_exc()}\")\n",
    "else:\n",
    "    print(\"⚠ Cannot save - df is empty. Check previous cells.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>WeightClassKg</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Division</th>\n",
       "      <th>Event</th>\n",
       "      <th>BodyweightKg</th>\n",
       "      <th>Equipment</th>\n",
       "      <th>Squat1Kg</th>\n",
       "      <th>Squat2Kg</th>\n",
       "      <th>...</th>\n",
       "      <th>Federation_meet</th>\n",
       "      <th>Date</th>\n",
       "      <th>MeetCountry</th>\n",
       "      <th>MeetState</th>\n",
       "      <th>MeetTown</th>\n",
       "      <th>MeetName</th>\n",
       "      <th>RuleSet</th>\n",
       "      <th>Sanctioned</th>\n",
       "      <th>MeetDate</th>\n",
       "      <th>WeightClassKg_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angie Belk Terry</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>47.0</td>\n",
       "      <td>M2</td>\n",
       "      <td>SBD</td>\n",
       "      <td>59.60</td>\n",
       "      <td>Wraps</td>\n",
       "      <td>38.56</td>\n",
       "      <td>47.63</td>\n",
       "      <td>...</td>\n",
       "      <td>365Strong</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>USA</td>\n",
       "      <td>NC</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Junior &amp; Senior National Powerlifting Champion...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dawn Bogart</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>42.0</td>\n",
       "      <td>M1</td>\n",
       "      <td>SBD</td>\n",
       "      <td>58.51</td>\n",
       "      <td>Single-ply</td>\n",
       "      <td>120.20</td>\n",
       "      <td>136.08</td>\n",
       "      <td>...</td>\n",
       "      <td>365Strong</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>USA</td>\n",
       "      <td>NC</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Junior &amp; Senior National Powerlifting Champion...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dawn Bogart</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Open</td>\n",
       "      <td>SBD</td>\n",
       "      <td>58.51</td>\n",
       "      <td>Single-ply</td>\n",
       "      <td>120.20</td>\n",
       "      <td>136.08</td>\n",
       "      <td>...</td>\n",
       "      <td>365Strong</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>USA</td>\n",
       "      <td>NC</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Junior &amp; Senior National Powerlifting Champion...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dawn Bogart</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Open</td>\n",
       "      <td>B</td>\n",
       "      <td>58.51</td>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>365Strong</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>USA</td>\n",
       "      <td>NC</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Junior &amp; Senior National Powerlifting Champion...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Destiny Dula</td>\n",
       "      <td>67.5</td>\n",
       "      <td>F</td>\n",
       "      <td>18.0</td>\n",
       "      <td>T3</td>\n",
       "      <td>BD</td>\n",
       "      <td>63.68</td>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>365Strong</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>USA</td>\n",
       "      <td>NC</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Junior &amp; Senior National Powerlifting Champion...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name WeightClassKg Sex   Age Division Event  BodyweightKg  \\\n",
       "0  Angie Belk Terry            60   F  47.0       M2   SBD         59.60   \n",
       "1       Dawn Bogart            60   F  42.0       M1   SBD         58.51   \n",
       "2       Dawn Bogart            60   F  42.0     Open   SBD         58.51   \n",
       "3       Dawn Bogart            60   F  42.0     Open     B         58.51   \n",
       "4      Destiny Dula          67.5   F  18.0       T3    BD         63.68   \n",
       "\n",
       "    Equipment  Squat1Kg  Squat2Kg  ...  Federation_meet       Date  \\\n",
       "0       Wraps     38.56     47.63  ...        365Strong 2016-10-29   \n",
       "1  Single-ply    120.20    136.08  ...        365Strong 2016-10-29   \n",
       "2  Single-ply    120.20    136.08  ...        365Strong 2016-10-29   \n",
       "3         Raw       NaN       NaN  ...        365Strong 2016-10-29   \n",
       "4         Raw       NaN       NaN  ...        365Strong 2016-10-29   \n",
       "\n",
       "   MeetCountry  MeetState   MeetTown  \\\n",
       "0          USA         NC  Charlotte   \n",
       "1          USA         NC  Charlotte   \n",
       "2          USA         NC  Charlotte   \n",
       "3          USA         NC  Charlotte   \n",
       "4          USA         NC  Charlotte   \n",
       "\n",
       "                                            MeetName  RuleSet  Sanctioned  \\\n",
       "0  Junior & Senior National Powerlifting Champion...      NaN         NaN   \n",
       "1  Junior & Senior National Powerlifting Champion...      NaN         NaN   \n",
       "2  Junior & Senior National Powerlifting Champion...      NaN         NaN   \n",
       "3  Junior & Senior National Powerlifting Champion...      NaN         NaN   \n",
       "4  Junior & Senior National Powerlifting Champion...      NaN         NaN   \n",
       "\n",
       "    MeetDate  WeightClassKg_numeric  \n",
       "0 2016-10-29                   60.0  \n",
       "1 2016-10-29                   60.0  \n",
       "2 2016-10-29                   60.0  \n",
       "3 2016-10-29                   60.0  \n",
       "4 2016-10-29                   67.5  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick preview\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "Name                             object\n",
      "WeightClassKg                    object\n",
      "Sex                              object\n",
      "Age                             float64\n",
      "Division                         object\n",
      "                              ...      \n",
      "MeetName                         object\n",
      "RuleSet                          object\n",
      "Sanctioned                       object\n",
      "MeetDate                 datetime64[ns]\n",
      "WeightClassKg_numeric           float64\n",
      "Length: 73, dtype: object\n",
      "\n",
      "Memory usage:\n",
      "4283.48 MB\n"
     ]
    }
   ],
   "source": [
    "# Basic info\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMemory usage:\")\n",
    "print(f\"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
