{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA Insights Summary\n",
        "\n",
        "This notebook synthesizes findings from all analyses and provides recommendations for the multi-factor scoring system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from utils import categorize_federation_testing_status\n",
        "\n",
        "print(\"Loading all analysis results...\")\n",
        "\n",
        "# Load saved metrics\n",
        "try:\n",
        "    experience_metrics = pd.read_parquet(\"../data/processed/experience_metrics.parquet\")\n",
        "    print(f\"✓ Experience metrics loaded: {len(experience_metrics):,} rows\")\n",
        "except:\n",
        "    print(\"✗ Experience metrics not found\")\n",
        "    experience_metrics = None\n",
        "\n",
        "try:\n",
        "    age_metrics = pd.read_parquet(\"../data/processed/age_metrics.parquet\")\n",
        "    print(f\"✓ Age metrics loaded: {len(age_metrics):,} rows\")\n",
        "except:\n",
        "    print(\"✗ Age metrics not found\")\n",
        "    age_metrics = None\n",
        "\n",
        "try:\n",
        "    meet_quality = pd.read_parquet(\"../data/processed/meet_quality_metrics.parquet\")\n",
        "    print(f\"✓ Meet quality metrics loaded: {len(meet_quality):,} rows\")\n",
        "except:\n",
        "    print(\"✗ Meet quality metrics not found\")\n",
        "    meet_quality = None\n",
        "\n",
        "try:\n",
        "    consistency_metrics = pd.read_parquet(\"../data/processed/consistency_metrics.parquet\")\n",
        "    print(f\"✓ Consistency metrics loaded: {len(consistency_metrics):,} rows\")\n",
        "except:\n",
        "    print(\"✗ Consistency metrics not found\")\n",
        "    consistency_metrics = None\n",
        "\n",
        "print(\"\\nAll metrics loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Findings by Factor\n",
        "\n",
        "### 1. Experience Factor\n",
        "### 2. Age Factor  \n",
        "### 3. Competition Quality Factor\n",
        "### 4. Consistency Factor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate summary statistics for each factor\n",
        "insights = {\n",
        "    'experience': {},\n",
        "    'age': {},\n",
        "    'quality': {},\n",
        "    'consistency': {}\n",
        "}\n",
        "\n",
        "if experience_metrics is not None:\n",
        "    # Add testing status if not present\n",
        "    if 'FederationTestingStatus' not in experience_metrics.columns:\n",
        "        # Load full dataset to get testing status\n",
        "        df_full = pd.read_parquet(\"../data/processed/full_dataset.parquet\")\n",
        "        df_full = categorize_federation_testing_status(df_full)\n",
        "        experience_metrics = experience_metrics.merge(\n",
        "            df_full[['Name', 'FederationTestingStatus']].drop_duplicates('Name'),\n",
        "            on='Name', how='left'\n",
        "        )\n",
        "    \n",
        "    insights['experience'] = {}\n",
        "    for testing_status in ['Drug Tested', 'Untested']:\n",
        "        status_metrics = experience_metrics[experience_metrics['FederationTestingStatus'] == testing_status]\n",
        "        if len(status_metrics) > 0:\n",
        "            insights['experience'][testing_status] = {\n",
        "                'avg_years': status_metrics['YearsCompeting'].mean(),\n",
        "                'avg_meets': status_metrics['TotalMeets'].mean(),\n",
        "                'correlation': status_metrics['YearsCompeting'].corr(status_metrics.get('Dots', status_metrics.get('Wilks', status_metrics.get('TotalKg', 0))))\n",
        "            }\n",
        "\n",
        "if age_metrics is not None:\n",
        "    insights['age'] = {\n",
        "        'avg_age': age_metrics['Age'].mean(),\n",
        "        'age_range': (age_metrics['Age'].min(), age_metrics['Age'].max()),\n",
        "        'correlation': age_metrics['Age'].corr(age_metrics.iloc[:, -1])  # Last column should be score\n",
        "    }\n",
        "\n",
        "if meet_quality is not None:\n",
        "    insights['quality'] = {}\n",
        "    for testing_status in ['Drug Tested', 'Untested']:\n",
        "        status_quality = meet_quality[meet_quality['FederationTestingStatus'] == testing_status]\n",
        "        if len(status_quality) > 0:\n",
        "            insights['quality'][testing_status] = {\n",
        "                'avg_competitors': status_quality['CompetitorCount'].mean(),\n",
        "                'avg_strength': status_quality['AvgScore'].mean(),\n",
        "                'elite_threshold': status_quality['AvgScore'].quantile(0.90)\n",
        "            }\n",
        "\n",
        "if consistency_metrics is not None:\n",
        "    # Add testing status if not present\n",
        "    if 'FederationTestingStatus' not in consistency_metrics.columns:\n",
        "        # Load full dataset to get testing status\n",
        "        df_full = pd.read_parquet(\"../data/processed/full_dataset.parquet\")\n",
        "        df_full = categorize_federation_testing_status(df_full)\n",
        "        consistency_metrics = consistency_metrics.merge(\n",
        "            df_full[['Name', 'FederationTestingStatus']].drop_duplicates('Name'),\n",
        "            on='Name', how='left'\n",
        "        )\n",
        "    \n",
        "    insights['consistency'] = {}\n",
        "    for testing_status in ['Drug Tested', 'Untested']:\n",
        "        status_metrics = consistency_metrics[consistency_metrics['FederationTestingStatus'] == testing_status]\n",
        "        if len(status_metrics) > 0:\n",
        "            insights['consistency'][testing_status] = {\n",
        "                'avg_cv': status_metrics['CV'].mean(),\n",
        "                'median_cv': status_metrics['CV'].median(),\n",
        "                'avg_peak_ratio': status_metrics['PeakToAvgRatio'].mean()\n",
        "            }\n",
        "\n",
        "print(\"=== Summary Insights ===\")\n",
        "for factor, data in insights.items():\n",
        "    print(f\"\\n{factor.upper()}:\")\n",
        "    for key, value in data.items():\n",
        "        print(f\"  {key}: {value}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
